name: Deploy to ECS

on:
  push:
    branches:
      - main

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
  ECS_CLUSTER: ${{ secrets.ECS_CLUSTER }}
  ECS_SERVICE: ${{ secrets.ECS_SERVICE }}
  ECS_TASK_DEFINITION: ecs-task-definition.json
  ECS_CONTAINER_NAME: ${{ secrets.ECS_CONTAINER_NAME }}
  ECS_SUBNETS: ${{ secrets.ECS_SUBNETS }} # comma-separated, e.g. subnet-a,subnet-b,subnet-c
  ECS_SECURITY_GROUPS: ${{ secrets.ECS_SECURITY_GROUPS }} # comma-separated, e.g. sg-123,sg-456

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - name: Install dependencies
        run: npm ci

      # Prisma migrations must run from inside AWS (private VPC); GitHub-hosted runners cannot reach RDS.

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

      - name: Render Amazon ECS task definition
        id: render-task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: ${{ env.ECS_TASK_DEFINITION }}
          container-name: ${{ env.ECS_CONTAINER_NAME }}
          image: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}
          environment-variables: |
            DATABASE_URL=${{ secrets.DATABASE_URL }}

      - name: Ensure CloudWatch log group exists (us-east-2)
        run: |
          set -euo pipefail
          REGION="us-east-2"
          GROUP="/ecs/civix"
          aws logs describe-log-groups --region "$REGION" --log-group-name-prefix "$GROUP" \
            --query 'logGroups[?logGroupName==`'"$GROUP"'`].logGroupName' --output text | grep -q "$GROUP" \
            || aws logs create-log-group --region "$REGION" --log-group-name "$GROUP"

      - name: Resolve failed Prisma migration in ECS (one-time)
        env:
          AWS_REGION: us-east-2
          CLUSTER: ${{ env.ECS_CLUSTER }}
          SUBNETS: ${{ env.ECS_SUBNETS }}
          SECURITY_GROUPS: ${{ env.ECS_SECURITY_GROUPS }}
          CONTAINER_NAME: ${{ env.ECS_CONTAINER_NAME }}
          LOG_GROUP: /ecs/civix
          APP_NAME: civix
          MIGRATION_NAME: 20250101000000_add-question-key
        run: |
          set -euo pipefail

          normalize_csv() {
            local input="$1"
            local -a items=()
            IFS=',' read -r -a raw <<< "$input"
            for item in "${raw[@]}"; do
              item="$(echo "$item" | xargs)"
              [ -n "$item" ] && items+=("$item")
            done
            printf '%s' "$(IFS=,; echo "${items[*]}")"
          }

          SUBNETS_CSV="$(normalize_csv "$SUBNETS")"
          SGS_CSV="$(normalize_csv "$SECURITY_GROUPS")"

          echo "Launching Prisma resolve task for migration: $MIGRATION_NAME"

          python3 - <<'PY' > overrides.json
          import json, os
          print(json.dumps({
            "containerOverrides": [{
              "name": os.environ["CONTAINER_NAME"],
              "command": ["npx","prisma","migrate","resolve","--applied", os.environ["MIGRATION_NAME"]]
            }]
          }))
          PY

          # Use the SAME task definition family your migrations use.
          # If your workflow already computed TASK_DEF_ARN earlier, set it here instead.
          TASK_DEF_ARN="$(aws ecs list-task-definitions --region "$AWS_REGION" --family-prefix "$APP_NAME" --sort DESC --max-items 1 --query 'taskDefinitionArns[0]' --output text)"
          echo "Using task definition: $TASK_DEF_ARN"

          aws ecs run-task \
            --region "$AWS_REGION" \
            --cluster "$CLUSTER" \
            --launch-type FARGATE \
            --task-definition "$TASK_DEF_ARN" \
            --network-configuration "awsvpcConfiguration={subnets=[$SUBNETS_CSV],securityGroups=[$SGS_CSV],assignPublicIp=ENABLED}" \
            --overrides file://overrides.json \
            --output json > resolve-run.json

          TASK_ARN="$(jq -r '.tasks[0].taskArn' resolve-run.json)"
          echo "Resolve Task ARN: $TASK_ARN"

          aws ecs wait tasks-stopped --region "$AWS_REGION" --cluster "$CLUSTER" --tasks "$TASK_ARN" || true

          DESC="$(aws ecs describe-tasks --region "$AWS_REGION" --cluster "$CLUSTER" --tasks "$TASK_ARN" --output json)"
          EXIT_CODE="$(echo "$DESC" | jq -r '.tasks[0].containers[0].exitCode // empty')"
          echo "Resolve exit code: $EXIT_CODE"

          # Manual CloudWatch fetch (works even if ECS doesn't populate logStreamName)
          TASK_ID="${TASK_ARN##*/}"
          STREAM="ecs/$APP_NAME/$TASK_ID"
          echo "CloudWatch log stream: $STREAM"
          aws logs get-log-events \
            --region "$AWS_REGION" \
            --log-group-name "$LOG_GROUP" \
            --log-stream-name "$STREAM" \
            --start-from-head \
            --query 'events[].message' \
            --output text || true

          if [ "$EXIT_CODE" != "0" ]; then
            echo "Resolve task failed."
            exit 1
          fi

          echo "Resolve completed successfully."

      - name: Run Prisma migrations in ECS
        env:
          CONTAINER_NAME: ${{ env.ECS_CONTAINER_NAME }}
          ECS_CLUSTER: ${{ env.ECS_CLUSTER }}
          ECS_SUBNETS: ${{ env.ECS_SUBNETS }}
          ECS_SECURITY_GROUPS: ${{ env.ECS_SECURITY_GROUPS }}
        shell: bash
        run: |
          set -euo pipefail

          CLUSTER="${{ env.ECS_CLUSTER }}"
          CONTAINER_NAME="$(printf '%s' "${{ env.ECS_CONTAINER_NAME }}" | tr -d '\r\n')"
          TASK_DEF_FILE="${{ steps.render-task-def.outputs.task-definition }}"

          TASK_DEF_ARN="$(aws ecs register-task-definition \
            --cli-input-json file://$TASK_DEF_FILE \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)"

          echo "Registered task def: $TASK_DEF_ARN"
          echo "Task def log config:"
          aws ecs describe-task-definition --task-definition "$TASK_DEF_ARN" \
            --query 'taskDefinition.{executionRoleArn:executionRoleArn, containers:containerDefinitions[].{name:name,log:logConfiguration}}' \
            --output json

          export ECS_SUBNETS="${{ env.ECS_SUBNETS }}"
          export ECS_SECURITY_GROUPS="${{ env.ECS_SECURITY_GROUPS }}"

          python3 - <<'PY' > overrides.json
          import json, os
          print(json.dumps({
            "containerOverrides": [{
              "name": os.environ["CONTAINER_NAME"],
              "command": ["sh", "-c", "npx prisma generate && npx prisma migrate deploy"]
            }]
          }))
          PY

          normalize_csv() {
            local input="$1"
            local -a items=()
            IFS=',' read -r -a raw <<< "$input"
            for item in "${raw[@]}"; do
              item="$(echo "$item" | xargs)"
              [ -n "$item" ] && items+=("$item")
            done
            printf '%s' "$(IFS=,; echo "${items[*]}")"
          }

          SUBNETS_CSV="$(normalize_csv "$ECS_SUBNETS")"
          SECURITY_GROUPS_CSV="$(normalize_csv "$ECS_SECURITY_GROUPS")"

          [ -z "$SUBNETS_CSV" ] && echo "ECS_SUBNETS empty" && exit 1
          [ -z "$SECURITY_GROUPS_CSV" ] && echo "ECS_SECURITY_GROUPS empty" && exit 1

          echo "Running migration task..."
          aws ecs run-task \
            --cluster "$CLUSTER" \
            --launch-type FARGATE \
            --task-definition "$TASK_DEF_ARN" \
            --network-configuration "awsvpcConfiguration={subnets=[$SUBNETS_CSV],securityGroups=[$SECURITY_GROUPS_CSV],assignPublicIp=ENABLED}" \
            --overrides file://overrides.json \
            --output json > run-task.json

          FAILURES_COUNT="$(jq '.failures | length' run-task.json)"
          if [ "$FAILURES_COUNT" != "0" ]; then
            echo "Run-task failures:"
            jq '.failures' run-task.json
            exit 1
          fi

          TASK_ARN="$(jq -r '.tasks[0].taskArn // empty' run-task.json)"
          [ -z "$TASK_ARN" ] && echo "No taskArn returned" && exit 1
          echo "Task ARN: $TASK_ARN"

          # ✅ Wait until ENI + log stream exist
          echo "Waiting for task to reach RUNNING..."
          aws ecs wait tasks-running --cluster "$CLUSTER" --tasks "$TASK_ARN" || true

          # Pull ENI + log stream (retry a few times because ENI can lag)
          ENI_ID=""
          LOG_STREAM=""
          for i in 1 2 3 4 5; do
            DESC="$(aws ecs describe-tasks --cluster "$CLUSTER" --tasks "$TASK_ARN" --output json)"
            ENI_ID="$(echo "$DESC" | jq -r '.tasks[0].attachments[]? | select(.type=="ElasticNetworkInterface") | .details[]? | select(.name=="networkInterfaceId") | .value' | head -n 1)"
            LOG_STREAM="$(echo "$DESC" | jq -r '.tasks[0].containers[0].logStreamName // empty')"
            [ -n "$ENI_ID" ] || [ -n "$LOG_STREAM" ] && break
            echo "ENI/log stream not ready yet (attempt $i)..."
            sleep 2
          done

          if [ -n "$ENI_ID" ]; then
            echo "ENI ID: $ENI_ID"
            PRIVATE_IP="$(aws ec2 describe-network-interfaces --network-interface-ids "$ENI_ID" --query 'NetworkInterfaces[0].PrivateIpAddress' --output text)"
            PUBLIC_IP="$(aws ec2 describe-network-interfaces --network-interface-ids "$ENI_ID" --query 'NetworkInterfaces[0].Association.PublicIp' --output text || true)"
            echo "ENI private IP: $PRIVATE_IP"
            echo "ENI public IP: ${PUBLIC_IP:-<none>}"
          else
            echo "No ENI ID found (can happen if the task exits fast)."
          fi

          echo "Waiting for task to stop..."
          aws ecs wait tasks-stopped --cluster "$CLUSTER" --tasks "$TASK_ARN"

          TASK_ID="${TASK_ARN##*/}"
          echo "Attempting manual CloudWatch log fetch..."
          echo "Log group: /ecs/civix"
          echo "Log stream: ecs/civix/$TASK_ID"
          aws logs get-log-events \
            --region us-east-2 \
            --log-group-name "/ecs/civix" \
            --log-stream-name "ecs/civix/$TASK_ID" \
            --start-from-head \
            --query 'events[].message' \
            --output text || true

          echo "Container statuses:"
          aws ecs describe-tasks --cluster "$CLUSTER" --tasks "$TASK_ARN" \
            --query 'tasks[0].containers[].{name:name,exitCode:exitCode,reason:reason,logStreamName:logStreamName,lastStatus:lastStatus}' \
            --output table

          echo "Recent log streams (if any):"
          aws logs describe-log-streams \
            --region us-east-2 \
            --log-group-name "/ecs/civix" \
            --order-by LastEventTime --descending \
            --max-items 10 \
            --query 'logStreams[].{name:logStreamName,lastEvent:lastEventTimestamp}' \
            --output table || true

          # After stop, fetch exit code + reason
          DESC2="$(aws ecs describe-tasks --cluster "$CLUSTER" --tasks "$TASK_ARN" --output json)"
          EXIT_CODE="$(echo "$DESC2" | jq -r '.tasks[0].containers[0].exitCode // empty')"
          STOPPED_REASON="$(echo "$DESC2" | jq -r '.tasks[0].stoppedReason // empty')"
          LOG_STREAM="$(echo "$DESC2" | jq -r '.tasks[0].containers[0].logStreamName // empty')"

          echo "Stopped reason: $STOPPED_REASON"
          echo "Migration exit code: $EXIT_CODE"
          echo "Log stream: $LOG_STREAM"

          # ✅ THIS is what you were missing: print Prisma logs on failure
          if [ "$EXIT_CODE" != "0" ]; then
            echo "Migration failed. Dumping CloudWatch logs..."
            if [ -n "$LOG_STREAM" ]; then
              aws logs get-log-events \
                --log-group-name "/ecs/civix" \
                --log-stream-name "$LOG_STREAM" \
                --start-from-head \
                --query 'events[].message' \
                --output text || true
            else
              echo "No log stream found on container."
            fi
            exit 1
          fi

          echo "Migration succeeded."

      - name: Deploy Amazon ECS task definition
        uses: aws-actions/amazon-ecs-deploy-task-definition@v2
        with:
          task-definition: ${{ steps.render-task-def.outputs.task-definition }}
          service: ${{ env.ECS_SERVICE }}
          cluster: ${{ env.ECS_CLUSTER }}
          wait-for-service-stability: true
